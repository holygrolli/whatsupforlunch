name: augustiner
on:
  workflow_dispatch:
  schedule:
    - cron: '10 10 * * 0'
permissions: 
  contents: write
  packages: write
  pull-request: write
jobs:
  download:
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/holygrolli/whatsupforlunch:main
    outputs:
      matrix: ${{ steps.setmatrix.outputs.matrix }}
    steps:
      - name: checkout
        uses: actions/checkout@v3
        with:
          ref: >-
            ${{
              github.event_name == 'schedule' && 'main' || ''
            }}
      - name: get new links
        shell: bash
        run: |
          WD=${PWD}
          mkdir -p tmp
          scrapy runspider locations/augustiner/scra.py --nolog | sort -u > tmp/scraped_links.txt
          cd tmp
          while IFS= read -r line; do
            curl -sOL $line
          done < <(comm -13 ../data/augustiner/scraped_done.txt scraped_links.txt)
      - id: setmatrix
        working-directory: tmp
        run: |
          matrixInput=$(find . -name '*.pdf' -printf '%P\n') # Creates array of all pdf files in tmp folder
          # Start Generate Json String
          echo "$matrixInput" | \
          jq --slurp --raw-input -c 'split("\n")[:-1] | map(select(length>0))' > matrix
          cat ./matrix
          # End Generate Json String
          matrixStringifiedObject=$(cat ./matrix) # Use this as jq @sh not working right
          echo "::set-output name=matrix::$matrixStringifiedObject"
      - name: Archive all pdfs
        uses: actions/upload-artifact@v3
        with:
          name: pdfs
          retention-days: 30
          path: |
            tmp
  process:
    needs: download
    if: ${{ needs.download.outputs.matrix != '' && toJson(fromJson(needs.download.outputs.matrix)) != '[]' }}
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/holygrolli/whatsupforlunch:main
    strategy:
      max-parallel: 1
      matrix:
        files: ${{fromJson(needs.download.outputs.matrix)}}
        # include:
        #   - files: Le-Casino-Speiseplan-KW26.pdf
    concurrency: singlethread
    steps:
    - name: checkout source code
      uses: actions/checkout@v3
      with:
        ref: >-
          ${{
            github.event_name == 'schedule' && 'main' || ''
          }}
    - name: fetch latest git
      if: ${{ !github.event.act }} # skip during local actions testing
      shell: bash
      run: |
        git config --system --add safe.directory $PWD
        git pull
    - name: Download pdf artifacts
      uses: actions/download-artifact@v3
      with:
        name: pdfs
        path: tmp
    - name: extract txt from ${{ matrix.files }}
      working-directory: tmp
      run: |
        pdftotext ${{ matrix.files }} Mittagskarte.txt
    - name: process txt with chatgpt
      working-directory: tmp
      env:
        OPENAI_API_KEY: ${{secrets.OPENAI_API_KEY}}
      shell: bash
      run: |
        python ../locations/augustiner/process_chatgpt.py ../locations/augustiner/prompt.txt Mittagskarte.txt
        mkdir -p ../data/augustiner
        cp final.json ../data/augustiner/$(date -d"$(jq -r 'keys[0]' final.json)" +%Y-%V).json
        CURRENTFILE=${{ matrix.files }}
        cat ../data/augustiner/scraped_done.txt <(echo $'\n'$(cat scraped_links.txt | grep ${CURRENTFILE%_separated*})) | sort -u | grep . > scraped_done.txt
        cp scraped_done.txt ../data/augustiner/scraped_done.txt
    - name: Archive all tmp files
      uses: actions/upload-artifact@v3
      with:
        name: ${{ matrix.files }}-processed
        retention-days: 5
        path: |
          tmp
    - name: Create Pull Request
      if: ${{ !github.event.act }}
      uses: peter-evans/create-pull-request@v5
      with:
        add-paths: |
          data
        branch: ${{ github.workflow }}-cron
        commit-message: "chore(data): automated scraping"
        labels: auto-approve-cron
